{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mask Detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPNdxHlLM/hGzty821mlwdW"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pq_BVSFal3Yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc467c0-ebab-44b7-8414-935dc0c53993"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44giNTwq-9aw"
      },
      "source": [
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKWQYJ3I_Qs9",
        "outputId": "00005609-1435-4a9f-b532-9a74a5474c2b"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import GlobalAveragePooling2D, Dropout, Dense, Activation, BatchNormalization, Conv2D, MaxPool2D, Flatten, MaxPooling2D\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.optimizers import SGD, Adam\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GFwXo6VAPFS"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\n",
        "from tensorflow.compat.v1 import InteractiveSession\n",
        "\n",
        "config = ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBGckiJJ6ELM"
      },
      "source": [
        "# **Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prj8BD_z-FLc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZntHocn-EKx"
      },
      "source": [
        "! cp \"/content/gdrive/My Drive/Projects/MaskDetection/faces1.zip\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyEJIdFD-EHr"
      },
      "source": [
        "! unzip faces1.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXCexMk652AP"
      },
      "source": [
        "MODEL_SAVE = 'service_type_model.h5'\n",
        "FAST_RUN = False\n",
        "IMAGE_WIDTH = 300\n",
        "IMAGE_HEIGHT = 300\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "IMAGE_CHANNELS = 1\n",
        "IMG_DIR = 'faces1/'\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg8jwfuKQ2AC"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gGS-p-Q-EFD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "2f5b7be8-47ba-4c58-f72e-7f327f13b66c"
      },
      "source": [
        "dataset = []\n",
        "\n",
        "for fold in os.listdir(IMG_DIR):\n",
        "    for filename in os.listdir(f'{IMG_DIR}/{fold}'):\n",
        "        dataset.append((f'{fold}/{filename}', fold))\n",
        "\n",
        "df = pd.DataFrame(dataset, columns=['filename', 'category'])\n",
        "df_train, df_test = train_test_split(df, random_state=42, stratify=df.category, test_size=.2)\n",
        "df_train['set'] = 'train'\n",
        "df_test['set'] = 'test'\n",
        "df = df_train.append(df_test)\n",
        "df.to_csv('dataset.csv', index=False)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>maskoff/maskoff (204).jpg</td>\n",
              "      <td>maskoff</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>maskon/augmented_image_216.jpg</td>\n",
              "      <td>maskon</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>maskon/novissimas (160).jpg</td>\n",
              "      <td>maskon</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1137</th>\n",
              "      <td>maskoff/unknown (933).jpg</td>\n",
              "      <td>maskoff</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>maskon/novissimas (216).jpg</td>\n",
              "      <td>maskon</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            filename category    set\n",
              "1817       maskoff/maskoff (204).jpg  maskoff  train\n",
              "439   maskon/augmented_image_216.jpg   maskon  train\n",
              "35       maskon/novissimas (160).jpg   maskon  train\n",
              "1137       maskoff/unknown (933).jpg  maskoff  train\n",
              "702      maskon/novissimas (216).jpg   maskon  train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWu9LbbE-D38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e52cc3bd-fd01-434f-84ca-7a92987772e5"
      },
      "source": [
        "df = pd.read_csv('dataset.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>category</th>\n",
              "      <th>set</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>maskoff/maskoff (204).jpg</td>\n",
              "      <td>maskoff</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>maskon/augmented_image_216.jpg</td>\n",
              "      <td>maskon</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>maskon/novissimas (160).jpg</td>\n",
              "      <td>maskon</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>maskoff/unknown (933).jpg</td>\n",
              "      <td>maskoff</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>maskon/novissimas (216).jpg</td>\n",
              "      <td>maskon</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                         filename category    set\n",
              "0       maskoff/maskoff (204).jpg  maskoff  train\n",
              "1  maskon/augmented_image_216.jpg   maskon  train\n",
              "2     maskon/novissimas (160).jpg   maskon  train\n",
              "3       maskoff/unknown (933).jpg  maskoff  train\n",
              "4     maskon/novissimas (216).jpg   maskon  train"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEa0ScdxRhlk"
      },
      "source": [
        "train_df = df[df.set == 'train'].reset_index(drop=True)\n",
        "validate_df = df[df.set == 'test'].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8Srf8iWSRTL",
        "outputId": "93fbe717-7a6a-4564-b2a4-5b554455cd6e"
      },
      "source": [
        "base_model = MobileNet(\n",
        "    weights= None, \n",
        "    include_top=False, \n",
        "    input_shape= (IMAGE_HEIGHT, IMAGE_WIDTH, IMAGE_CHANNELS)\n",
        ")\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256,activation='relu')(x) \n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfVNsWnMSOMr"
      },
      "source": [
        "callbacks_list = [\n",
        "    ModelCheckpoint('model-{epoch:03d}.model', monitor='val_accuracy', verbose=1, \n",
        "                    save_best_only=True, mode='max'),\n",
        "    EarlyStopping(monitor='val_accuracy', patience=12),\n",
        "    ReduceLROnPlateau(monitor='val_accuracy', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5, \n",
        "                                            min_lr=0.00001)\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIVMvVYQS9so"
      },
      "source": [
        "def add_noise(img):\n",
        "    '''Add random noise to an image'''\n",
        "    VARIABILITY = 8\n",
        "    deviation = VARIABILITY*random.random()\n",
        "    noise = np.random.normal(0, deviation, img.shape)\n",
        "    img += noise\n",
        "    np.clip(img, 0., 255.)\n",
        "    return img\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    brightness_range=[0.2, 1.6],\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=0, \n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1, \n",
        "    shear_range=0.2, \n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True, \n",
        "    fill_mode=\"nearest\",\n",
        "    preprocessing_function=add_noise,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4HP4mfITDdR",
        "outputId": "f3519a6a-dd8d-4e75-befe-49a0972bcf32"
      },
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df, \n",
        "    IMG_DIR, \n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode = 'grayscale',\n",
        "    class_mode='categorical',\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1498 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 4 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLZTXvR3THC0",
        "outputId": "e1901d1d-9b6f-45f1-8fb4-04ccdb319edb"
      },
      "source": [
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_dataframe(\n",
        "    validate_df, \n",
        "    IMG_DIR,\n",
        "    x_col='filename',\n",
        "    y_col='category',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    color_mode = 'grayscale',\n",
        "    class_mode='categorical',\n",
        "    shuffle=False,\n",
        "    batch_size=BATCH_SIZE\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 374 validated image filenames belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 2 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
            "  .format(n_invalid, x_col)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvxtbZXtTXGs"
      },
      "source": [
        "## Fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSrK-PQCTSQq"
      },
      "source": [
        "total_train = train_df.shape[0]\n",
        "total_validate = validate_df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_X9VaiB0uOeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebc056bb-ebd2-4b06-e656-c04cd97b70db"
      },
      "source": [
        "epochs=50 if FAST_RUN else 50\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator, \n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=total_validate//BATCH_SIZE,\n",
        "    steps_per_epoch=total_train//BATCH_SIZE,\n",
        "    callbacks=callbacks_list\n",
        ")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 25s 542ms/step - loss: 0.7443 - accuracy: 0.5580 - val_loss: 0.7001 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.50000, saving model to model-001.model\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 20s 437ms/step - loss: 0.6277 - accuracy: 0.6453 - val_loss: 0.6921 - val_accuracy: 0.4942\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.50000\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 20s 432ms/step - loss: 0.5572 - accuracy: 0.7128 - val_loss: 0.6978 - val_accuracy: 0.4883\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.50000\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 20s 428ms/step - loss: 0.5003 - accuracy: 0.7558 - val_loss: 0.6976 - val_accuracy: 0.4971\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.50000\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 20s 426ms/step - loss: 0.4120 - accuracy: 0.8090 - val_loss: 0.7099 - val_accuracy: 0.5088\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.50000 to 0.50877, saving model to model-005.model\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 19s 419ms/step - loss: 0.3714 - accuracy: 0.8383 - val_loss: 0.7341 - val_accuracy: 0.5058\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.50877\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 20s 426ms/step - loss: 0.3053 - accuracy: 0.8813 - val_loss: 0.9460 - val_accuracy: 0.5029\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.50877\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 20s 424ms/step - loss: 0.3132 - accuracy: 0.8724 - val_loss: 0.9334 - val_accuracy: 0.5117\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.50877 to 0.51170, saving model to model-008.model\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 19s 414ms/step - loss: 0.2794 - accuracy: 0.8943 - val_loss: 1.2425 - val_accuracy: 0.5088\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.51170\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 19s 422ms/step - loss: 0.2842 - accuracy: 0.8772 - val_loss: 1.3496 - val_accuracy: 0.5058\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.51170\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 20s 433ms/step - loss: 0.2228 - accuracy: 0.9124 - val_loss: 1.7473 - val_accuracy: 0.5175\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.51170 to 0.51754, saving model to model-011.model\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 19s 411ms/step - loss: 0.1949 - accuracy: 0.9185 - val_loss: 1.2007 - val_accuracy: 0.5146\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.51754\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 20s 426ms/step - loss: 0.1924 - accuracy: 0.9253 - val_loss: 1.5355 - val_accuracy: 0.5000\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.51754\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 19s 417ms/step - loss: 0.1936 - accuracy: 0.9247 - val_loss: 1.1073 - val_accuracy: 0.6053\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.51754 to 0.60526, saving model to model-014.model\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 19s 423ms/step - loss: 0.1483 - accuracy: 0.9468 - val_loss: 0.3502 - val_accuracy: 0.8684\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.60526 to 0.86842, saving model to model-015.model\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 20s 431ms/step - loss: 0.1440 - accuracy: 0.9482 - val_loss: 0.1893 - val_accuracy: 0.9006\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.86842 to 0.90058, saving model to model-016.model\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 20s 434ms/step - loss: 0.1540 - accuracy: 0.9504 - val_loss: 0.2074 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.90058 to 0.96199, saving model to model-017.model\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 20s 424ms/step - loss: 0.1534 - accuracy: 0.9390 - val_loss: 0.0949 - val_accuracy: 0.9620\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.96199\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 20s 426ms/step - loss: 0.1230 - accuracy: 0.9577 - val_loss: 0.1093 - val_accuracy: 0.9211\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.96199\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 20s 430ms/step - loss: 0.1301 - accuracy: 0.9509 - val_loss: 0.1032 - val_accuracy: 0.9415\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.96199\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 20s 426ms/step - loss: 0.1077 - accuracy: 0.9626 - val_loss: 0.1668 - val_accuracy: 0.9766\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.96199 to 0.97661, saving model to model-021.model\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 19s 412ms/step - loss: 0.0938 - accuracy: 0.9678 - val_loss: 0.3353 - val_accuracy: 0.9415\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.97661\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 20s 433ms/step - loss: 0.1023 - accuracy: 0.9645 - val_loss: 0.0126 - val_accuracy: 0.9561\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.97661\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 20s 425ms/step - loss: 0.0879 - accuracy: 0.9714 - val_loss: 0.1486 - val_accuracy: 0.9708\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.97661\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 20s 428ms/step - loss: 0.0811 - accuracy: 0.9674 - val_loss: 0.0458 - val_accuracy: 0.9886\n",
            "\n",
            "Epoch 00025: val_accuracy improved from 0.97661 to 0.98864, saving model to model-025.model\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 19s 418ms/step - loss: 0.0661 - accuracy: 0.9760 - val_loss: 0.0050 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.98864\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 19s 422ms/step - loss: 0.0630 - accuracy: 0.9789 - val_loss: 0.0500 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.98864\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 19s 424ms/step - loss: 0.0548 - accuracy: 0.9843 - val_loss: 0.0151 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.98864\n",
            "\n",
            "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 19s 422ms/step - loss: 0.0720 - accuracy: 0.9741 - val_loss: 0.0287 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00029: val_accuracy did not improve from 0.98864\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 20s 424ms/step - loss: 0.0649 - accuracy: 0.9755 - val_loss: 0.0132 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.98864\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 20s 424ms/step - loss: 0.0511 - accuracy: 0.9809 - val_loss: 0.0104 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.98864\n",
            "\n",
            "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 19s 422ms/step - loss: 0.0405 - accuracy: 0.9863 - val_loss: 0.0332 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00032: val_accuracy improved from 0.98864 to 0.99123, saving model to model-032.model\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 19s 416ms/step - loss: 0.0624 - accuracy: 0.9783 - val_loss: 0.0472 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.99123\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 19s 419ms/step - loss: 0.0522 - accuracy: 0.9808 - val_loss: 0.0416 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.99123\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 20s 424ms/step - loss: 0.0465 - accuracy: 0.9871 - val_loss: 0.0753 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00035: val_accuracy improved from 0.99123 to 0.99415, saving model to model-035.model\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 19s 412ms/step - loss: 0.0614 - accuracy: 0.9775 - val_loss: 0.0740 - val_accuracy: 0.9854\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.99415\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 19s 423ms/step - loss: 0.0301 - accuracy: 0.9877 - val_loss: 0.0113 - val_accuracy: 0.9915\n",
            "\n",
            "Epoch 00037: val_accuracy did not improve from 0.99415\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 19s 419ms/step - loss: 0.0560 - accuracy: 0.9843 - val_loss: 0.0022 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00038: val_accuracy did not improve from 0.99415\n",
            "\n",
            "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 19s 419ms/step - loss: 0.0622 - accuracy: 0.9761 - val_loss: 0.0195 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00039: val_accuracy did not improve from 0.99415\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 19s 422ms/step - loss: 0.0483 - accuracy: 0.9836 - val_loss: 0.0234 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00040: val_accuracy did not improve from 0.99415\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 19s 420ms/step - loss: 0.0520 - accuracy: 0.9809 - val_loss: 0.0192 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00041: val_accuracy did not improve from 0.99415\n",
            "\n",
            "Epoch 00041: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 19s 421ms/step - loss: 0.0552 - accuracy: 0.9809 - val_loss: 0.0046 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00042: val_accuracy did not improve from 0.99415\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 19s 424ms/step - loss: 0.0424 - accuracy: 0.9857 - val_loss: 0.0053 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00043: val_accuracy did not improve from 0.99415\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 19s 424ms/step - loss: 0.0518 - accuracy: 0.9823 - val_loss: 0.0263 - val_accuracy: 0.9883\n",
            "\n",
            "Epoch 00044: val_accuracy did not improve from 0.99415\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 20s 426ms/step - loss: 0.0532 - accuracy: 0.9870 - val_loss: 0.0691 - val_accuracy: 0.9912\n",
            "\n",
            "Epoch 00045: val_accuracy did not improve from 0.99415\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 20s 428ms/step - loss: 0.0516 - accuracy: 0.9836 - val_loss: 0.0516 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00046: val_accuracy did not improve from 0.99415\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 20s 431ms/step - loss: 0.0553 - accuracy: 0.9829 - val_loss: 0.0735 - val_accuracy: 0.9942\n",
            "\n",
            "Epoch 00047: val_accuracy did not improve from 0.99415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_KTXbvjcCzb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}